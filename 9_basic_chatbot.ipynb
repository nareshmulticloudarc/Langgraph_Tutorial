{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "361ab168",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph, START, END\n",
    "from typing import TypedDict,Literal, Annotated\n",
    "from langchain_core.messages import BaseMessage, HumanMessage\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langgraph.checkpoint.memory import MemorySaver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "107de115",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph.message import add_messages\n",
    "class ChatState(TypedDict):\n",
    "    messages: Annotated[list[BaseMessage], add_messages]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a609ab60",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI()\n",
    "\n",
    "def chat_node_func(state: ChatState):\n",
    "\n",
    "    #take user query form state\n",
    "    messages = state['messages']\n",
    "    #send to llm\n",
    "    response = llm.invoke(messages)\n",
    "    #store response to state\n",
    "    return {'messages': [response]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7b9fcfe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "checkpointer = MemorySaver()\n",
    "graph=StateGraph(ChatState)\n",
    "graph.add_node('chat_node', chat_node_func)\n",
    "\n",
    "graph.add_edge(START, 'chat_node')\n",
    "graph.add_edge( 'chat_node', END)\n",
    "\n",
    "chatbot = graph.compile(checkpointer=checkpointer)\n",
    "\n",
    "#graph.compile()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d8512ed1",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Checkpointer requires one or more of the following 'configurable' keys: thread_id, checkpoint_ns, checkpoint_id",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      1\u001b[39m initial_state={\n\u001b[32m      2\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mmessages\u001b[39m\u001b[33m'\u001b[39m: [HumanMessage(content=\u001b[33m'\u001b[39m\u001b[33mWhat is the capital of India\u001b[39m\u001b[33m'\u001b[39m)]\n\u001b[32m      3\u001b[39m }\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m \u001b[43mchatbot\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43minitial_state\u001b[49m\u001b[43m)\u001b[49m[\u001b[33m'\u001b[39m\u001b[33mmessages\u001b[39m\u001b[33m'\u001b[39m][-\u001b[32m1\u001b[39m].content\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\windowsadmin\\Documents\\Langgraph_Tutorial\\myenv\\Lib\\site-packages\\langgraph\\pregel\\main.py:3094\u001b[39m, in \u001b[36mPregel.invoke\u001b[39m\u001b[34m(self, input, config, context, stream_mode, print_mode, output_keys, interrupt_before, interrupt_after, durability, **kwargs)\u001b[39m\n\u001b[32m   3091\u001b[39m chunks: \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any] | Any] = []\n\u001b[32m   3092\u001b[39m interrupts: \u001b[38;5;28mlist\u001b[39m[Interrupt] = []\n\u001b[32m-> \u001b[39m\u001b[32m3094\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   3095\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   3096\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3097\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3098\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mupdates\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mvalues\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[32m   3099\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mvalues\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\n\u001b[32m   3100\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3101\u001b[39m \u001b[43m    \u001b[49m\u001b[43mprint_mode\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprint_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3102\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_keys\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3103\u001b[39m \u001b[43m    \u001b[49m\u001b[43minterrupt_before\u001b[49m\u001b[43m=\u001b[49m\u001b[43minterrupt_before\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3104\u001b[39m \u001b[43m    \u001b[49m\u001b[43minterrupt_after\u001b[49m\u001b[43m=\u001b[49m\u001b[43minterrupt_after\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3105\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdurability\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdurability\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3106\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3107\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   3108\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mvalues\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\n\u001b[32m   3109\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m:\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\windowsadmin\\Documents\\Langgraph_Tutorial\\myenv\\Lib\\site-packages\\langgraph\\pregel\\main.py:2551\u001b[39m, in \u001b[36mPregel.stream\u001b[39m\u001b[34m(self, input, config, context, stream_mode, print_mode, output_keys, interrupt_before, interrupt_after, durability, subgraphs, debug, **kwargs)\u001b[39m\n\u001b[32m   2534\u001b[39m run_manager = callback_manager.on_chain_start(\n\u001b[32m   2535\u001b[39m     \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   2536\u001b[39m     \u001b[38;5;28minput\u001b[39m,\n\u001b[32m   2537\u001b[39m     name=config.get(\u001b[33m\"\u001b[39m\u001b[33mrun_name\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28mself\u001b[39m.get_name()),\n\u001b[32m   2538\u001b[39m     run_id=config.get(\u001b[33m\"\u001b[39m\u001b[33mrun_id\u001b[39m\u001b[33m\"\u001b[39m),\n\u001b[32m   2539\u001b[39m )\n\u001b[32m   2540\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   2541\u001b[39m     \u001b[38;5;66;03m# assign defaults\u001b[39;00m\n\u001b[32m   2542\u001b[39m     (\n\u001b[32m   2543\u001b[39m         stream_modes,\n\u001b[32m   2544\u001b[39m         output_keys,\n\u001b[32m   2545\u001b[39m         interrupt_before_,\n\u001b[32m   2546\u001b[39m         interrupt_after_,\n\u001b[32m   2547\u001b[39m         checkpointer,\n\u001b[32m   2548\u001b[39m         store,\n\u001b[32m   2549\u001b[39m         cache,\n\u001b[32m   2550\u001b[39m         durability_,\n\u001b[32m-> \u001b[39m\u001b[32m2551\u001b[39m     ) = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_defaults\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2552\u001b[39m \u001b[43m        \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2553\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2554\u001b[39m \u001b[43m        \u001b[49m\u001b[43mprint_mode\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprint_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2555\u001b[39m \u001b[43m        \u001b[49m\u001b[43moutput_keys\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2556\u001b[39m \u001b[43m        \u001b[49m\u001b[43minterrupt_before\u001b[49m\u001b[43m=\u001b[49m\u001b[43minterrupt_before\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2557\u001b[39m \u001b[43m        \u001b[49m\u001b[43minterrupt_after\u001b[49m\u001b[43m=\u001b[49m\u001b[43minterrupt_after\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2558\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdurability\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdurability\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2559\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2560\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m checkpointer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m durability \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   2561\u001b[39m         warnings.warn(\n\u001b[32m   2562\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33m`durability` has no effect when no checkpointer is present.\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   2563\u001b[39m         )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\windowsadmin\\Documents\\Langgraph_Tutorial\\myenv\\Lib\\site-packages\\langgraph\\pregel\\main.py:2421\u001b[39m, in \u001b[36mPregel._defaults\u001b[39m\u001b[34m(self, config, stream_mode, print_mode, output_keys, interrupt_before, interrupt_after, durability)\u001b[39m\n\u001b[32m   2419\u001b[39m     checkpointer = \u001b[38;5;28mself\u001b[39m.checkpointer\n\u001b[32m   2420\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m checkpointer \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m config.get(CONF):\n\u001b[32m-> \u001b[39m\u001b[32m2421\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   2422\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mCheckpointer requires one or more of the following \u001b[39m\u001b[33m'\u001b[39m\u001b[33mconfigurable\u001b[39m\u001b[33m'\u001b[39m\u001b[33m \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   2423\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mkeys: thread_id, checkpoint_ns, checkpoint_id\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   2424\u001b[39m     )\n\u001b[32m   2425\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m CONFIG_KEY_RUNTIME \u001b[38;5;129;01min\u001b[39;00m config.get(CONF, {}):\n\u001b[32m   2426\u001b[39m     store: BaseStore | \u001b[38;5;28;01mNone\u001b[39;00m = config[CONF][CONFIG_KEY_RUNTIME].store\n",
      "\u001b[31mValueError\u001b[39m: Checkpointer requires one or more of the following 'configurable' keys: thread_id, checkpoint_ns, checkpoint_id"
     ]
    }
   ],
   "source": [
    "initial_state={\n",
    "    'messages': [HumanMessage(content='What is the capital of India')]\n",
    "}\n",
    "\n",
    "chatbot.invoke(initial_state)['messages'][-1].content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b36ee7f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User:  Hello My Name is Naresh\n",
      "AI: Hello Naresh! How can I assist you today?\n",
      "User:  I'm expert in AI\n",
      "AI: That's great to hear, Naresh! It's always fantastic to connect with someone who is knowledgeable in the field of artificial intelligence. Is there anything specific you would like to discuss or share about AI?\n",
      "User:  What is my Name?\n",
      "AI: Your name is Naresh, as you mentioned in your first message. How can I assist you further, Naresh?\n",
      "User:  What is my NAme?\n",
      "AI: Your name is Naresh. Is there something specific you would like to know or discuss, Naresh?\n",
      "User:  bye\n"
     ]
    }
   ],
   "source": [
    "thread_id = '1'\n",
    "while True:\n",
    "    user_message = input('Type here:')\n",
    "    print('User: ', user_message)\n",
    "    if user_message.strip().lower() in ['exit','quite','bye']:\n",
    "        break\n",
    "\n",
    "    config={'configurable':{'thread_id': thread_id}}\n",
    "    response = chatbot.invoke({'messages': [HumanMessage(content=user_message)]}, config=config)\n",
    "\n",
    "    print('AI:', response['messages'][-1].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7a7c806",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StateSnapshot(values={'messages': [HumanMessage(content='Hello My Name is Naresh', additional_kwargs={}, response_metadata={}, id='4936d208-be4d-4912-9c3e-d3936f264b49'), AIMessage(content='Hello Naresh! How can I assist you today?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 11, 'prompt_tokens': 13, 'total_tokens': 24, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'id': 'chatcmpl-CW0RbiuZVxRh9x2tROUXQn5YZAwSB', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--154ac3da-e4c0-4a8a-952c-aa8a38bd1386-0', usage_metadata={'input_tokens': 13, 'output_tokens': 11, 'total_tokens': 24, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}), HumanMessage(content=\"I'm expert in AI\", additional_kwargs={}, response_metadata={}, id='a8dd9aeb-c996-4656-b62f-bb8a37512315'), AIMessage(content=\"That's great to hear, Naresh! It's always fantastic to connect with someone who is knowledgeable in the field of artificial intelligence. Is there anything specific you would like to discuss or share about AI?\", additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 41, 'prompt_tokens': 37, 'total_tokens': 78, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'id': 'chatcmpl-CW0RvxXjVACn9vx7Ec8MPDfTmKz1i', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--31347b0f-c4c6-4baa-a4c2-eb78772da774-0', usage_metadata={'input_tokens': 37, 'output_tokens': 41, 'total_tokens': 78, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}), HumanMessage(content='What is my Name?', additional_kwargs={}, response_metadata={}, id='56ccdf13-f11e-486e-99d1-364e45213e79'), AIMessage(content='Your name is Naresh, as you mentioned in your first message. How can I assist you further, Naresh?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 24, 'prompt_tokens': 91, 'total_tokens': 115, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'id': 'chatcmpl-CW0S3ERAunCKtg7IZVoesXuU62GFg', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--fe75801a-1453-4833-b769-113dc2883ed9-0', usage_metadata={'input_tokens': 91, 'output_tokens': 24, 'total_tokens': 115, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}), HumanMessage(content='What is my NAme?', additional_kwargs={}, response_metadata={}, id='e0db0446-dcb2-4310-9f7d-77196252bb61'), AIMessage(content='Your name is Naresh. Is there something specific you would like to know or discuss, Naresh?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 21, 'prompt_tokens': 129, 'total_tokens': 150, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'id': 'chatcmpl-CW0TpNnXAuKRDHbfxGXE8FpRCtWQz', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--79eee753-2129-481f-bc8e-fd34f4ef58ee-0', usage_metadata={'input_tokens': 129, 'output_tokens': 21, 'total_tokens': 150, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]}, next=(), config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f0b4cad-9e24-628e-800a-7da884b1309b'}}, metadata={'source': 'loop', 'step': 10, 'parents': {}}, created_at='2025-10-29T13:26:18.036289+00:00', parent_config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f0b4cad-981f-69f6-8009-a991ec879629'}}, tasks=(), interrupts=())"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chatbot.get_state(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8c687fb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
